<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Theresa Szczepanski">

<title>CheckIn1.qmd</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">DACSS758</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./CheckIn1.html" aria-current="page"> 
<span class="menu-text">Check In 1</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#article-1" id="toc-article-1" class="nav-link active" data-scroll-target="#article-1">Article 1</a></li>
  <li><a href="#article-2" id="toc-article-2" class="nav-link" data-scroll-target="#article-2">Article 2</a></li>
  <li><a href="#final-project" id="toc-final-project" class="nav-link" data-scroll-target="#final-project">Final Project</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Check in 1</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Theresa Szczepanski </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<p>Find <strong>TWO academic journal articles using Text Analysis Approaches</strong>&nbsp;in your field, or of the topics you are interested in. For each article, answer the questions below:</p>
<section id="article-1" class="level1">
<h1>Article 1</h1>
<p>In Uurrutia and Araya’s paper “Do Written Responses to Open-Ended Questions on Fourth Grade Online Formative Assessments in Mathematics Help Predict Scores on End-of-Year Standardized Tests?”, the authors explore the use of student responses to open-ended formative assessment questions to predict student performance on end-of-year tests. <span class="citation" data-cites="Urrutia22">(<a href="#ref-Urrutia22" role="doc-biblioref">Urrutia F. 2022</a>)</span><br>
</p>
<p><br>
1. What is this paper’s research question?<br>
</p>
<p>The papers research question is: “To what extent do students’ short, written answers to teacher-designed, open-ended questions in weekly online formative tests help improve predictions of performance on end-of-the-year national multiple-choice standardized assessments?” <span class="citation" data-cites="Urrutia22">(<a href="#ref-Urrutia22" role="doc-biblioref">Urrutia F. 2022</a>)</span><br>
</p>
<p><br>
2. What data does the paper use? How are the data collected?<br>
</p>
<p>The authors used a database of chilean students’ questions and answers from an online assessment platform called <em>ConectaIdeas.</em> Students completed formative assessments consisting of closed-ended (multiple choice) and open-ended (free-response) mathematics questions. The authors had the responses from 464 fourth grade students to 16,618 open-ended questions and 621,575 closed-ended questions. The authors used these responses and student performance data on the Sistema de Medición de la Calidad de la Educación (SIMCE) exam, a national exam given annually to Chilean students to build a model to predict student performance on SIMCE exams.</p>
<p><br>
3. What is the hypotheses of the paper?&nbsp;<br>
</p>
<p><strong>Hypothesis:</strong> A predictive model of 4th grade student performance on the end of year SIMCE assessment that includes regressors taken from students’ responses to open-ended mathematics questions will outperform a baseline predictive model that includes only students’ scores on closed-ended mathematics questions.</p>
<p><br>
4. What text-as-data methods do the author(s) use? For example, sentiment analysis, classification, topic model, named-entity recognition, topic analysis, word embedding, etc.<br>
</p>
<p>The authors used two prediction models. One model would <strong><em>classify</em></strong> open-ended mathematics questions into one of 6 categories.</p>
<p>The second model would <strong><em>classify</em></strong> student responses as either <em>coherent</em> or <em>incoherent</em><strong>.</strong> Incoherent answers were answers that consisted of noisy text, such as emojis or curse words as well as nonsensical responses.</p>
<p><br>
5. Based on your understanding of the paper, what is the usage of each text-as-data method? For example, sentiment analysis detects the sentiment of a sentence, such as fear, anger, etc.</p>
<p>The researchers used <strong>classification</strong> to develop models to predict if a student’s answer to an open-ended question was <em>coherent</em>. They used student answers to open-ended questions in 2019 and the corresponding teacher’s <strong>classification</strong> of responses as either <em>incoherent</em> or <em>coherent</em> to train the model.&nbsp;</p>
<p>They also used <strong>classification</strong> to develop models to categorize open-ended questions into different types:</p>
<ol type="1">
<li><p>Calculate without explaining</p></li>
<li><p>Calculate with explaining</p></li>
<li><p>Choice and/or affirmation</p></li>
<li><p>Compare quantities</p></li>
<li><p>Procedure and content knowledge</p></li>
<li><p>Other</p></li>
</ol>
<p>The authors also extracted several linguistic features from the the student responses. These included: Number of <strong>dep/NumMod</strong> tokens and number of <strong>tag/Num</strong> tokens. They referenced other possible dependencies from this list: <a href="#0">https://universaldependencies.org/u/dep/</a>.<br>
</p>
<p><br>
6. What are the findings of the paper?<br>
</p>
<p>In testing, 83.5% of the time, the Open-ended model, which included regressors using linguistic features of student open-response answers, was better than the baseline model at predicting student performance on the end of year exam in terms of <span class="math inline">\(𝑅^2\)</span> <span class="citation" data-cites="Urrutia22">(<a href="#ref-Urrutia22" role="doc-biblioref">Urrutia F. 2022</a>)</span>. Also, the correlation matrix of the Open-ended model was “more homogeneous and null than the that of the baseline model” indicating that the “Open-ended model regressors correlate less with each other than the baseline model regressors” <span class="citation" data-cites="Urrutia22">(<a href="#ref-Urrutia22" role="doc-biblioref">Urrutia F. 2022</a>)</span>.</p>
<p><br>
7. What is your take on it?<br>
</p>
<p>I think that it was very interesting that the authors were able to parse out student written responses as <em>coherent</em> or <em>incoherent.</em> I think that it is useful to categorize student responses that are filled with noisy text or emojis into a distinct category from student responses that are incoherent because the mathematics is illogical. Noisy text from a student indicates something about the student’s emotional state and is distinct from latent math ability. I found the features: “Ratio of Incoherent responses” to be very interesting. I can see how a student who is overhwelmed with writing or explanations might exhibit differences from other students with this variable. The other linguistic features seemed to me to be more indicative of a student’s overall writing skills. I see how this coupled with their response to multiple choice problems can give a more accurate picture of a students’ overall skill profile than multiple choice responses alone. The correlation matrix seems to suggest that the variables the authors constructed are measuring something seemingly independent from the latent skills measured by the multiple choice responses.</p>
<p><br>
8. <strong>(Optional)</strong> If you find the paper helpful to your research, try to find the replication file of the paper.&nbsp;</p>
<p>I looked for a replication file and could not find one. I also looked on the author’s homepage. Perhaps since this involved student work it isn’t published?</p>
</section>
<section id="article-2" class="level1">
<h1>Article 2</h1>
<p>In the article <em>Framework for Classroom Student Grading with Open-Ended Questions: A Text-Mining Approach,</em> the authors apply text analysis techniques to student responses to open-ended questions in several grade level and subject areas<span class="citation" data-cites="Vairinhos22">(<a href="#ref-Vairinhos22" role="doc-biblioref">Vairinhos VM. 2022</a>)</span>.</p>
<p><br>
1. What is this paper’s research question?</p>
<p>Can text-mining be used to “extract objective, relevant, reliable and valid features” from student responses to open-ended questions (OEQ), in a way to allow the teacher to “construct, in real time, informed, unbiased and fact-based assessments” of student learning <span class="citation" data-cites="Vairinhos22">(<a href="#ref-Vairinhos22" role="doc-biblioref">Vairinhos VM. 2022</a>)</span>?</p>
<p><br>
2. What data does the paper use? How are the data collected?</p>
<p>The researchers collected three sets of observational data of students’ answers to tests with open response questions in Portuguese schools. The first data set was collected from student responses to questions on the official examinations of the Portuguese public educational system’s 12th year students. The responses were rated manually by teachers according to a rubric. The second data set consisted of 12th year student responses to open-response formative assessment questions in a Sociology class. The third data set consisted of University students’ response to open-response formative assessment questions in an Economics class. These data were stored in excel sheets with each row corresponding to an individual student’s response to a given question.</p>
<p><br>
3. What is the hypotheses of the paper?&nbsp;</p>
<p><strong>Hypothesis:</strong> A classification model created from descriptive statistics on student responses to open-response questions will provide teachers with “valid and reliable summaries” of these texts.</p>
<p><br>
4. What text-as-data methods do the author(s) use? For example, sentiment analysis, classification, topic model, named-entity recognition, topic analysis, word embedding, etc.</p>
<p>The authors used <strong>token extraction</strong> and <strong>topic modeling</strong> to create linguistic features that they could summarize with descriptive statistics. The authors then built a model that estimates a students language and subject matter content skills to <strong>classify</strong> the quality of the overall response.</p>
<p><br>
5. Based on your understanding of the paper, what is the usage of each text-as-data method? For example, sentiment analysis detects the sentiment of a sentence, such as fear, anger, etc.</p>
<p>The authors used <strong>token extraction</strong> to gather information about students’ general use of language. They also used <strong>topic modeling</strong> to estimate how much of a student’s response contained text that was subadjacent to the topic of the question. The authors performed summary statistics on the linguistic features in student responses to create features in their <strong>classification</strong> model. The authors built a model that included as features estimates of a student’s <em>lexical diversity</em> , a student’s <em>capability to structure text,</em> and a student’s level of <em>subject matter competence</em>. With these features they used a student’s language and subject matter content skills to <strong>classify</strong> the quality of the overall response. The authors produced several visual representations using dendograms and biplots of the information in the classification models in the hope to give teachers quick visual summaries of key information from a student’s written response that a teacher could then combine with their observations of the student’s work to assign a grade.</p>
<p><br>
6. What are the findings of the paper?</p>
<p>The authors found that the correlation between official classifications of the texts from a grading panel and the classifications assigned by a Portuguese teacher hired for the research project were of the same magnitude as the correlations obtained between those teachers and results obtained by the authors’ model (although both correlations were surprisingly low). The authors also found that there was no significant difference between the distributions of standardized results obtained by the teachers and those suggested by the model.</p>
<p><br>
7. What is your take on it?&nbsp;<br>
</p>
<p>I think that it is interesting to see the authors try to provide teachers with systems to more-efficiently grade open response items. This is a challenge for many teachers in the humanities. The authors noted in their findings that it was surprising that “the correlation between scores allocated by the official human correctors and those obtained by a Portuguese teacher hired by the second author” were “low” <em>but</em> of the same magnitude as the correlation of the model to the official correctors. This suggests to me that there is still a lot of work to be done to make this tool a valid and reliable estimate of how trained scoring panels would score the responses. If this model could be improved, could it eventually be more valid and reliable than a randomly selected teacher?</p>
</section>
<section id="final-project" class="level1">
<h1>Final Project</h1>
<p>After reading the articles, think about the final project you want to do in this course, and answer the questions below:</p>
<p><br>
1. What research topic you want to study? Do you have a specific research question?</p>
<p>I work for a public charter school in Massachusetts. Our students in Grades 5-10 are tested annually in Mathematics, English Language Arts, and Science. I am interested in using the student performance data to identify areas of weakness in our program in terms of curricular alignment. For every question on a given assessment, the state releases an <strong>item description</strong> detailing what was asked of students and the corresponding average score earned by students in our school as well as the average score earned by students across Massachusetts.</p>
<p><strong><em>My research question is</em></strong>: “Can test item descriptions on MCAS assessments be mined to extract features associated with student performance trends?”</p>
<p><br>
2. Do you have any hypothesis/expected answer to your research question?</p>
<p>I have already found statistically significant patterns in student performance associated with an item’s content reporting category in every subject and grade level at our school. When interviewing one of our experienced teachers who has historical success with student achievement in English Language Arts (ELA), she identified specific things that she believes all kids need to practice for success with (ELA), such as “synthesizing multiple texts”, “reading non-fiction”, and “identifying text features”. These are requirements in questions that can be mined from item descriptions but not from an item’s reporting category or standard description. Our students have historically performed weaker on the 7th grade English Language Arts exam than on the 6th and 8th grade exams. This suggests a curricular issue. I’ve already identified reporting categories in which our students have performed relatively weaker on this assessment. I suspect that within these reporting categories there exist patterns to the types of questions or tasks that our students struggle with. This could provide valuable information for teachers to adjust their instruction and instructional materials.</p>
<p>Similarly, in Mathematics I have identified specific content reporting categories that are relative weaknesses at different grade levels; however, this does not take into account the differences in questions like those Uurrutia and Araya classified in open-ended Math prompts. I would be curious to see if our students are weaker in items that ask them to evaluate an expression (apply technical skills) vs.&nbsp;construct or interpret a mathematical model (conceptual understanding). This would be very interesting information for teachers.</p>
<p><strong><em>Hypotheses</em></strong>:</p>
<p><strong><em>H1</em></strong>: A predictive model of 7th grade student performance on 7th grade English Language Arts assessment items that includes regressors taken from the test item descriptions will outperform a baseline predictive model that includes only a given test item’s content reporting category.</p>
<p><strong><em>H2</em></strong>: A predictive model of 6th grade student performance on 6th grade Mathematics assessment items that includes regressors taken from the test item descriptions will outperform a baseline predictive model that includes only a given test item’s content reporting category.</p>
<p><br>
3. What are some potential data sources?</p>
<p>I can scrape the <a href="https://profiles.doe.mass.edu/mcas/mcasitems2.aspx?grade=07&amp;subjectcode=ELA&amp;linkid=10&amp;orgcode=04830000&amp;fycode=2023&amp;orgtypecode=5&amp;">Department of Elementary and Secondary Educations’ accountability page</a>. It includes tables for all Next Generation MCAS tests (beginning in 2018) and text descriptions for all test items. I have actually already done this for the High School Science Exams in my Python course last fall. The structures of the tables are similar for the other exams.</p>
<p><br>
4. Is any of the text-as-data methods you identified in the journal articles may be helpful to your research?</p>
<p>In Uurrutia and Araya’s paper, they used <strong><em>classification</em></strong> to categorize open-ended mathematics questions into different types. I would like to classify the MCAS questions into different categories using the item descriptions.</p>
<p>For the Mathematics items, I would also like to use <strong>topic modeling</strong> to identify different topics within a given content reporting category. For example, Grade 6 students are assessed in the category <em>Geometry</em> on their ability to “Solve real-world and mathematical problems involving area, surface area, and volume.” I would like to parse out if there are distinctions between their performance on tasks involving <em>area</em> versus tasks involving <em>volume</em>. Being able to classify a problem as an <em>area</em> versus <em>volume</em> problem would allow me to do this. On a broader level, I would like to distinguish between items that ask students to apply technical or <em>computational</em> skills versus constructing or interpreting models (<em>conceptual understanding</em>).</p>
<p>For the English Language Arts items, I would like to classify items as to whether or not they require the “synthesis of multiple texts” and whether or not they require the analysis of “text features”.</p>
<p><br>
At this phase, you might have more questions than answers. Document all those questions.</p>
<ol type="1">
<li><p>I have also downloaded PDFs of all of the released paper-based versions of the MCAS tests. Here is an <a href="https://www.doe.mass.edu/mcas/2023/release/g5-math.pdf">example of a Math test</a>. Do you think it would be possible to parse out the text of each question into a data frame? The question texts themselves would also be interesting to analyze. I was wondering if you think it is an achievable task. If so, I’m curious to see more about how to set up a corpus with texts contained in PDF files.</p></li>
<li><p>For any subject and grade level, my data set of text would consist of approximately 200 items and their corresponding text descriptions. Is that large enough?</p></li>
<li><p>The Urrutia and Araya article discussed creating linguistic features using <strong>dep/NumMod</strong> tokens and <strong>tag/Num</strong> tokens. I was wondering if there is a good place for me to read about and understand them as a concept?</p></li>
<li><p>The Varinhos article discusses the use of topic modeling. This is something I would be interested in applying. Is there a good place to read about the fundamentals of topic modeling?</p></li>
</ol>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Urrutia22" class="csl-entry" role="listitem">
Urrutia F., Araya R. 2022. <span>“Do Written Responses to Open-Ended Questions on Fourth-Grade Online Formative Assessments in Mathematics Help Predict Scores on End-of-Year Standardized Tests?”</span> <em>Journal of Intelligence</em> 10 (4): 97–111. <a href="https://doi.org/10.3390/jintelligence10040082">https://doi.org/10.3390/jintelligence10040082</a>.
</div>
<div id="ref-Vairinhos22" class="csl-entry" role="listitem">
Vairinhos VM., Matos F., Pereira LA. 2022. <span>“Framework for Classroom Student Grading with Open-Ended Questions: A Text-Mining Approach.”</span> <em>Mathematics</em> 10 (2). <a href="https://doi.org/10.3390/math10214152">https://doi.org/10.3390/math10214152</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>